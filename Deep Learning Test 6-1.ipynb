{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90247b8c",
   "metadata": {},
   "source": [
    "## Scenario 1\n",
    "#### Problem Statement\n",
    "- **The dataset consists of 2-Dimensional spectrograms of radio signals from space collected at the SETI Instituteby  the Allen  Telescope  Array.The  objective  is  to classify the radio signalsfrom outer spaceinto one of four classes. Dataset DescriptionSETI Dataset**\n",
    "\n",
    "##### •Training Data: otrain_images: Normalized values of Pixels otrain_labels: Stored as One-Hot Encoded data\n",
    "##### •Validation Data: oval_images: Normalized values of Pixels oval_labels: Stored as One-Hot Encoded data\n",
    "##### •Classes: “squiggle”, “narrowband”, “narrowbanddrd”, and “noise”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe74d2a",
   "metadata": {},
   "source": [
    "### Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652eb8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from livelossplot.tf_keras import PlotLossesCallback\n",
    "from sklearn import metrics\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout,Flatten, Conv2D\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, MaxPooling2D\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import warnings;warnings.simplefilter('ignore')\n",
    "%matplotlib inline\n",
    "print('Tensorflow version:', tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6197ef",
   "metadata": {},
   "source": [
    "#### Load and Pre-process the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab85795",
   "metadata": {},
   "source": [
    "### Load the dataset using the pandas read_csvfunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6de25c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Images = pd.read_csv(r\"C:\\Users\\Shivani Dussa\\Downloads\\dataset\\train\\images.csv\",header = None)\n",
    "Train_Labels = pd.read_csv(r\"C:\\Users\\Shivani Dussa\\Downloads\\dataset\\train\\labels.csv\",header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba5ad4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_Images = pd.read_csv(r\"C:\\Users\\Shivani Dussa\\Downloads\\dataset\\valid\\images (1).csv\",header = None)\n",
    "val_Labels = pd.read_csv(r\"C:\\Users\\Shivani Dussa\\Downloads\\dataset\\valid\\labels (1).csv\",header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ebdfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Images.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c629bed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e01caaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_Images.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a0b2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_Labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3498f7c1",
   "metadata": {},
   "source": [
    "### Check the shape of the training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc5f836",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training data shape:\")\n",
    "print(Train_Images.shape)\n",
    "print(Train_Labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51a357b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Validation set shape:\")\n",
    "print(val_Images.shape)\n",
    "print(val_Labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c63d49e",
   "metadata": {},
   "source": [
    "### Reshape the training and validation images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c87352",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = Train_Images.values.reshape(3200, 64, 128, 1)\n",
    "x_val = val_Images.values.reshape(800, 64, 128, 1)\n",
    "\n",
    "y_train = Train_Labels.values\n",
    "y_val = val_Labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f60c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96907a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8b1ea8",
   "metadata": {},
   "source": [
    "### Visualize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbde981f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0, figsize=(12,12))\n",
    "for i in range(1,3):\n",
    "    plt.subplot(1,2,i)\n",
    "    img = np.squeeze(x_train[np.random.randint(0, x_train.shape[0])]) # np.squeeze is used to delete non  useful dimension in (64,128,1) and transform the shape into (64,128) in order to fit into plt.imshow\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(img,cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a84505",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0, figsize=(12,12))\n",
    "for i in range(1,5):\n",
    "    plt.subplot(1,4,i)\n",
    "    img = np.squeeze(x_train[np.random.randint(0, x_train.shape[0])]) # np.squeeze is used to delete non  useful dimension in (64,128,1) and transform the shape into (64,128) in order to fit into plt.imshow\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(img,cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c9c429",
   "metadata": {},
   "source": [
    "### Create Training and Validation Data Generators using Keras Image DataGenerator function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddd7a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
    "\n",
    "datagen_train = ImageDataGenerator(horizontal_flip=True)\n",
    "datagen_train.fit(x_train)\n",
    "\n",
    "datagen_val = ImageDataGenerator(horizontal_flip=True)\n",
    "datagen_val.fit(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdeed667",
   "metadata": {},
   "source": [
    "### Design a Convolutional Neural Network (CNN) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808846c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Input, Dropout,Flatten, Conv2D\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, MaxPooling2D\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228ccd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# 1st CNN layer \n",
    "model.add(Conv2D(32,(5,5), padding='same', input_shape=(64, 128,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "# 2nd CNN layer\n",
    "model.add(Conv2D(64,(5,5), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "# Flattening\n",
    "model.add(Flatten())\n",
    "\n",
    "# Dense Layer\n",
    "model.add(Dense(1024))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e2cfb3",
   "metadata": {},
   "source": [
    "### Compile the Modelusing Adam optimizer, categorical_crossentropy loss function, and accuracy metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f836b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_learning_rate = 0.005\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate,decay_steps=5,decay_rate=0.96,staircase=True)   \n",
    "\n",
    "optimizer = Adam(learning_rate=lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea8d1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161fc09d",
   "metadata": {},
   "source": [
    "### Print the Model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1c9435",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d3940c",
   "metadata": {},
   "source": [
    "### Train the Modelwith batch_size = 32 & epochs = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7d5ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\"model_weights.h5\", monitor='val_loss',\n",
    "                             save_weights_only=True, mode='min', verbose=0)\n",
    "callbacks = [PlotLossesCallback(), checkpoint]\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1600aacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(datagen_train.flow(x_train, y_train, batch_size=batch_size, shuffle=True),\n",
    "    steps_per_epoch=len(x_train)//batch_size,\n",
    "    validation_data = datagen_val.flow(x_val, y_val, batch_size=batch_size, shuffle=True),\n",
    "    validation_steps = len(x_val)//batch_size,\n",
    "    epochs=12,\n",
    "    callbacks=checkpoint\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aecbbe4",
   "metadata": {},
   "source": [
    "### Evaluate the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8b9a1f",
   "metadata": {},
   "source": [
    "#### Use the model.evaluatefunction to evaluate the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc32aee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46046f19",
   "metadata": {},
   "source": [
    "#### Print a Classification Reportand the accuracy score (classification accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fec424",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "\n",
    "y_true = np.argmax(y_val, 1)\n",
    "y_pred = np.argmax(model.predict(x_val), 1)\n",
    "print(metrics.classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab19688",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification accuracy: %0.6f\" % metrics.accuracy_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399cbab7",
   "metadata": {},
   "source": [
    "- The accuracy is 74% "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac614ee",
   "metadata": {},
   "source": [
    "#### Display a Confusion Matrix to evaluate the performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b00f316",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d19ee3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels =  ['squiggle', 'narrowband', 'narrowbanddrd','noise']\n",
    "\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(metrics.confusion_matrix(y_true, y_pred, normalize='true'), annot=True, ax = ax, cmap = plt.cm.viridis);\n",
    "\n",
    "ax.set_title('Confusion Matrix') \n",
    "ax.xaxis.set_ticklabels(labels)\n",
    "ax.yaxis.set_ticklabels(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b9622d",
   "metadata": {},
   "source": [
    "# Scenario 2\n",
    "## Problem Statement\n",
    "- **Theobjective  is  to  detect  Moving  Cars  inavideo  file using OpenCV using the HaarCascade_car.xml file and then, you will use OpenCV to detect the License plates of a Car using the HaarCascade_russian_plate_numberXMLfileTasks to be performed.**\n",
    "- •Prepare a detailed python notebook using OpenCVto detect Moving Cars in a video\n",
    "- •Import Required Libraries\n",
    "- •Create a Classifier usingthe HaarCascade_car xml file\n",
    "- •Load the Video \n",
    "- •Detect the Moving Cars using the Classifier\n",
    "- •Display the Results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd40760",
   "metadata": {},
   "source": [
    "#### Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb07abbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import cv2\n",
    "from PIL import Image\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21d0518",
   "metadata": {},
   "source": [
    "#### Create a Classifier usingthe HaarCascade_car xml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8a21d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cascade\n",
    "car_cascade = cv2.CascadeClassifier(r\"C:\\Users\\Shivani Dussa\\Downloads\\DL - MCT Data\\HaarCascade_cars.xml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8550c0d2",
   "metadata": {},
   "source": [
    "#### Load the Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035e5986",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_video = cv2.VideoCapture(r\"C:\\Users\\Shivani Dussa\\Downloads\\Pexels Videos 2053100.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef98ed10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixColor(image):\n",
    "    return(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d9ff2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "Video(r\"C:\\Users\\Shivani Dussa\\Downloads\\Pexels Videos 2053100.mp4\",embed = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5eb928",
   "metadata": {},
   "source": [
    "### Detect the Moving Cars using the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6468b4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "while load_video.isOpened():\n",
    "    \n",
    "    time.sleep(.05)\n",
    "    ret, frame = load_video.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    cars = car_cascade.detectMultiScale(gray, 1.4,2)\n",
    "    \n",
    "    #Display the results \n",
    "    for (x,y,w,h) in cars:\n",
    "        cv2.rectangle(frame, (x,y), (x+w, y+h), (0,0,255), 2)\n",
    "        cv2.imshow('Cars',frame)\n",
    "    \n",
    "    if cv2.waitKey(1) == 13:\n",
    "        break\n",
    "        \n",
    "load_video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668d6c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I detected the cars in the vide to checks run this code u can the cars detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7807426",
   "metadata": {},
   "source": [
    "### To detect the license plate of a car"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bef9d3",
   "metadata": {},
   "source": [
    "### Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7a8c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97df62a5",
   "metadata": {},
   "source": [
    "#### Load the Image using the imread function of OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd65dacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(r\"C:\\Users\\Shivani Dussa\\Downloads\\cars.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d86e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "image2 = cv2.imread(r\"C:\\Users\\Shivani Dussa\\Downloads\\car4.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77e9051",
   "metadata": {},
   "source": [
    "#### Pre-process the Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0e4092",
   "metadata": {},
   "source": [
    "#### Create a function to convert the image using cv2.Color(img, cv2.COLOR_BGR2RGB) function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abfd34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "converting_image = cv2.cvtColor(image2,cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5288c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "converting_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb71f530",
   "metadata": {},
   "source": [
    "#### Display the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f928650",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgplot = plt.imshow(image2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900ae380",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgplot = plt.imshow(converting_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a611d39",
   "metadata": {},
   "source": [
    "#### Create afunction for a classifier using the HaarCascade_russian_plate_number.xml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986f69f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_NumberPlate = cv2.CascadeClassifier(r\"C:\\Users\\Shivani Dussa\\Downloads\\DL - MCT Data\\haarcascade_russian_plate_number.xml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bb56b1",
   "metadata": {},
   "source": [
    "#### Detect the Car License Plates using the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e023e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = car_NumberPlate.detectMultiScale(converting_image,scaleFactor = 1.2, minNeighbors = 5,minSize = (25,25))\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(converting_image,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    plate = converting_image[y: y+h, x:x+w]\n",
    "    plate = cv2.blur(plate,ksize=(20,20))\n",
    "    \n",
    "    # Display the results\n",
    "    converting_image[y: y+h, x:x+w] = plate\n",
    "\n",
    "cv2.imshow('plates',converting_image)\n",
    "if cv2.waitKey(0) & 0xFF == ord('q'):\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "91b74a02",
   "metadata": {},
   "source": [
    "Run to see the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307bc80b",
   "metadata": {},
   "source": [
    "## Thank You "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
