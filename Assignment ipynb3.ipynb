{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd828ae1",
   "metadata": {},
   "source": [
    "### **`.ipynb file 3`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57ca1c3",
   "metadata": {},
   "source": [
    "**Marks: 25**\n",
    ">**Problem Statement**<br>\n",
    "The dataset is similar to MNIST, but includes images of certain clothing and accessory. The objective is to classify images into specific classes using single layer perceptron and multilayer perceptron.<br>\n",
    "<br>\n",
    "**Dataset Description**\n",
    "- Total Images: 70,000 \n",
    "- Train Images: 60,000 \n",
    "- Test Images: 10,000 \n",
    "- Image Size: 28 X 28 \n",
    "- Classes: 'T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot' \n",
    "\n",
    ">**Tasks to be Performed:**\n",
    "As a part of this assignment you will be performing the following tasks:\n",
    "- Prepare a detailed python notebook(similar to this one) using muli-layer perceptron for classifing the images from [MNIST Fashion Dataset ](https://github.com/zalandoresearch/fashion-mnist) with best accuracy\n",
    "- Prepare the dataset for the model\n",
    "- Develop Single Layer Perceptron model for classifying the handwritten digits\n",
    "- Plot the change in accuracy per epochs\n",
    "- Evaluate the model on the testing data\n",
    "- Analyse the model summary\n",
    "- Add hidden layer to the model to make it Multi-Layer Perceptron\n",
    "- Add Dropout to prevent overfitting and check its effect on accuracy\n",
    "- Increasing the number of Hidden Layer neuron and check its effect on accuracy\n",
    "- Use different optimizers and check its effect on accuracy\n",
    "- Increase the hidden layers and check its effect on accuracy\n",
    "- Manipulate the batch_size and epochs and check its effect on accuracy\n",
    "\n",
    "**Answer:** What parameters should be choosen to get best accuracy on classifying the images into various categories?\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "839cab39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c65df847",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare the dataset for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09ac8517",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r\"C:\\Users\\Shivani Dussa\\Downloads\\fashion-mnist_train.csv\\fashion-mnist_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7674389",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(r\"C:\\Users\\Shivani Dussa\\Downloads\\fashion-mnist_test.csv\\fashion-mnist_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f591ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 785)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a93817f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 785)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b43f35d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_fashion = pd.concat([train,test]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "224ba27f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 785)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_fashion.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09b96448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      2       0       0       0       0       0       0       0       0   \n",
       "1      9       0       0       0       0       0       0       0       0   \n",
       "2      6       0       0       0       0       0       0       0       5   \n",
       "3      0       0       0       0       1       2       0       0       0   \n",
       "4      3       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0        30        43         0   \n",
       "3       0  ...         3         0         0         0         0         1   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_fashion.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79cac944",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Develop Single Layer Perceptron model for classifying the handwritten digits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6592fe62",
   "metadata": {},
   "source": [
    "\n",
    "- Prepare a detailed python notebook(similar to this one) using muli-layer perceptron for classifing the images from [MNIST Fashion Dataset ](https://github.com/zalandoresearch/fashion-mnist) with best accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f610f8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6250972a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_fashion = keras.datasets.fashion_mnist\n",
    "(X_train,y_train),(X_test,y_test) = mnist_fashion.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e07e451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(60000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)   # 60k,28,28 shape is in 3Dimensional \n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed832d57",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
       "          0,   0,  13,  73,   0,   0,   1,   4,   0,   0,   0,   0,   1,\n",
       "          1,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "          0,  36, 136, 127,  62,  54,   0,   0,   0,   1,   3,   4,   0,\n",
       "          0,   3],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,\n",
       "          0, 102, 204, 176, 134, 144, 123,  23,   0,   0,   0,   0,  12,\n",
       "         10,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0, 155, 236, 207, 178, 107, 156, 161, 109,  64,  23,  77, 130,\n",
       "         72,  15],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
       "         69, 207, 223, 218, 216, 216, 163, 127, 121, 122, 146, 141,  88,\n",
       "        172,  66],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   1,   1,   0,\n",
       "        200, 232, 232, 233, 229, 223, 223, 215, 213, 164, 127, 123, 196,\n",
       "        229,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        183, 225, 216, 223, 228, 235, 227, 224, 222, 224, 221, 223, 245,\n",
       "        173,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        193, 228, 218, 213, 198, 180, 212, 210, 211, 213, 223, 220, 243,\n",
       "        202,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   3,   0,  12,\n",
       "        219, 220, 212, 218, 192, 169, 227, 208, 218, 224, 212, 226, 197,\n",
       "        209,  52],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0,  99,\n",
       "        244, 222, 220, 218, 203, 198, 221, 215, 213, 222, 220, 245, 119,\n",
       "        167,  56],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,  55,\n",
       "        236, 228, 230, 228, 240, 232, 213, 218, 223, 234, 217, 217, 209,\n",
       "         92,   0],\n",
       "       [  0,   0,   1,   4,   6,   7,   2,   0,   0,   0,   0,   0, 237,\n",
       "        226, 217, 223, 222, 219, 222, 221, 216, 223, 229, 215, 218, 255,\n",
       "         77,   0],\n",
       "       [  0,   3,   0,   0,   0,   0,   0,   0,   0,  62, 145, 204, 228,\n",
       "        207, 213, 221, 218, 208, 211, 218, 224, 223, 219, 215, 224, 244,\n",
       "        159,   0],\n",
       "       [  0,   0,   0,   0,  18,  44,  82, 107, 189, 228, 220, 222, 217,\n",
       "        226, 200, 205, 211, 230, 224, 234, 176, 188, 250, 248, 233, 238,\n",
       "        215,   0],\n",
       "       [  0,  57, 187, 208, 224, 221, 224, 208, 204, 214, 208, 209, 200,\n",
       "        159, 245, 193, 206, 223, 255, 255, 221, 234, 221, 211, 220, 232,\n",
       "        246,   0],\n",
       "       [  3, 202, 228, 224, 221, 211, 211, 214, 205, 205, 205, 220, 240,\n",
       "         80, 150, 255, 229, 221, 188, 154, 191, 210, 204, 209, 222, 228,\n",
       "        225,   0],\n",
       "       [ 98, 233, 198, 210, 222, 229, 229, 234, 249, 220, 194, 215, 217,\n",
       "        241,  65,  73, 106, 117, 168, 219, 221, 215, 217, 223, 223, 224,\n",
       "        229,  29],\n",
       "       [ 75, 204, 212, 204, 193, 205, 211, 225, 216, 185, 197, 206, 198,\n",
       "        213, 240, 195, 227, 245, 239, 223, 218, 212, 209, 222, 220, 221,\n",
       "        230,  67],\n",
       "       [ 48, 203, 183, 194, 213, 197, 185, 190, 194, 192, 202, 214, 219,\n",
       "        221, 220, 236, 225, 216, 199, 206, 186, 181, 177, 172, 181, 205,\n",
       "        206, 115],\n",
       "       [  0, 122, 219, 193, 179, 171, 183, 196, 204, 210, 213, 207, 211,\n",
       "        210, 200, 196, 194, 191, 195, 191, 198, 192, 176, 156, 167, 177,\n",
       "        210,  92],\n",
       "       [  0,   0,  74, 189, 212, 191, 175, 172, 175, 181, 185, 188, 189,\n",
       "        188, 193, 198, 204, 209, 210, 210, 211, 188, 188, 194, 192, 216,\n",
       "        170,   0],\n",
       "       [  2,   0,   0,   0,  66, 200, 222, 237, 239, 242, 246, 243, 244,\n",
       "        221, 220, 193, 191, 179, 182, 182, 181, 176, 166, 168,  99,  58,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  40,  61,  44,  72,  41,  35,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "780be618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4485a802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28, 28), (28, 28))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape,X_test[9].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5ce6a47c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[69]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebff1dc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x25e034e6970>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X_train[69])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f512ceca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2c8c5260f40>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c176005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2c8c52bdd90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[96])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35bd6928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[96]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36b0c013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# X_train is 60000 rows of 28x28 values; we reshape it to # 60000 x 784. \n",
    "RESHAPED = 784                        # resolution 28x28  = 784 its a 2 Dimensional converted \n",
    "X_train = X_train.reshape(60000, RESHAPED) \n",
    "X_test = X_test.reshape(10000, RESHAPED) \n",
    "\n",
    "# Data is converted into float32 to use 32-bit precision # when training a neural network \n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32') \n",
    "\n",
    "# Normalizing the input to be within the range [0,1]\n",
    "X_train /= 255                                         # X_train = X_train / 255\n",
    "#intensity of each pixel is divided by 255, the maximum intensity value\n",
    "X_test /= 255\n",
    "\n",
    "print(X_train.shape[0], 'train samples') \n",
    "print(X_test.shape[0], 'test samples') \n",
    "\n",
    "# One-hot representation of the labels.\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10) \n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "36d1282f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb036754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (60000, 10), (10000, 784), (10000, 10))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,y_train.shape,X_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb8e09c",
   "metadata": {},
   "source": [
    "- **Develop Single Layer Perceptron model for classifying the handwritten digits**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e84f044d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ee206a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0 = Sequential()\n",
    "model_0.add(Dense(10,input_shape = (784,),name = 'dense_layer',activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c393bac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_layer (Dense)          (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f75a1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the model\n",
    "model_0.compile(optimizer = 'SGD',loss = 'categorical_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30afb635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  1/375 [..............................] - ETA: 0s - loss: 2.5494 - accuracy: 0.0547WARNING:tensorflow:From C:\\Users\\Shivani Dussa\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "  2/375 [..............................] - ETA: 13s - loss: 2.4970 - accuracy: 0.0547WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_end` time: 0.0681s). Check your callbacks.\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.2440 - accuracy: 0.6226 - val_loss: 0.8917 - val_accuracy: 0.7255\n",
      "Epoch 2/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.8204 - accuracy: 0.7380 - val_loss: 0.7527 - val_accuracy: 0.7598\n",
      "Epoch 3/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.7264 - accuracy: 0.7668 - val_loss: 0.6900 - val_accuracy: 0.7782\n",
      "Epoch 4/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.6758 - accuracy: 0.7824 - val_loss: 0.6504 - val_accuracy: 0.7883\n",
      "Epoch 5/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.6423 - accuracy: 0.7934 - val_loss: 0.6245 - val_accuracy: 0.7957\n",
      "Epoch 6/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.6179 - accuracy: 0.8005 - val_loss: 0.6039 - val_accuracy: 0.8020\n",
      "Epoch 7/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5991 - accuracy: 0.8059 - val_loss: 0.5878 - val_accuracy: 0.8064\n",
      "Epoch 8/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5839 - accuracy: 0.8111 - val_loss: 0.5751 - val_accuracy: 0.8094\n",
      "Epoch 9/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5714 - accuracy: 0.8143 - val_loss: 0.5640 - val_accuracy: 0.8134\n",
      "Epoch 10/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5608 - accuracy: 0.8175 - val_loss: 0.5562 - val_accuracy: 0.8161\n",
      "Epoch 11/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5517 - accuracy: 0.8208 - val_loss: 0.5474 - val_accuracy: 0.8164\n",
      "Epoch 12/30\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.5438 - accuracy: 0.8230 - val_loss: 0.5403 - val_accuracy: 0.8188\n",
      "Epoch 13/30\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.5367 - accuracy: 0.8247 - val_loss: 0.5338 - val_accuracy: 0.8207\n",
      "Epoch 14/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5305 - accuracy: 0.8259 - val_loss: 0.5287 - val_accuracy: 0.8206\n",
      "Epoch 15/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5249 - accuracy: 0.8283 - val_loss: 0.5232 - val_accuracy: 0.8233\n",
      "Epoch 16/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5199 - accuracy: 0.8293 - val_loss: 0.5189 - val_accuracy: 0.8247\n",
      "Epoch 17/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5150 - accuracy: 0.8315 - val_loss: 0.5147 - val_accuracy: 0.8264\n",
      "Epoch 18/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5108 - accuracy: 0.8319 - val_loss: 0.5110 - val_accuracy: 0.8278\n",
      "Epoch 19/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5068 - accuracy: 0.8324 - val_loss: 0.5074 - val_accuracy: 0.8278\n",
      "Epoch 20/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5032 - accuracy: 0.8331 - val_loss: 0.5055 - val_accuracy: 0.8295\n",
      "Epoch 21/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4998 - accuracy: 0.8344 - val_loss: 0.5022 - val_accuracy: 0.8286\n",
      "Epoch 22/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4965 - accuracy: 0.8360 - val_loss: 0.4984 - val_accuracy: 0.8310\n",
      "Epoch 23/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4936 - accuracy: 0.8366 - val_loss: 0.4959 - val_accuracy: 0.8314\n",
      "Epoch 24/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4908 - accuracy: 0.8377 - val_loss: 0.4936 - val_accuracy: 0.8311\n",
      "Epoch 25/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4883 - accuracy: 0.8377 - val_loss: 0.4907 - val_accuracy: 0.8334\n",
      "Epoch 26/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4857 - accuracy: 0.8388 - val_loss: 0.4890 - val_accuracy: 0.8336\n",
      "Epoch 27/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4833 - accuracy: 0.8398 - val_loss: 0.4882 - val_accuracy: 0.8340\n",
      "Epoch 28/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4810 - accuracy: 0.8401 - val_loss: 0.4855 - val_accuracy: 0.8332\n",
      "Epoch 29/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4790 - accuracy: 0.8411 - val_loss: 0.4832 - val_accuracy: 0.8353\n",
      "Epoch 30/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4769 - accuracy: 0.8411 - val_loss: 0.4813 - val_accuracy: 0.8363\n"
     ]
    }
   ],
   "source": [
    "#Training the model\n",
    "log_dir = \"logs/fit/model0\"\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = log_dir,histogram_freq = 1)\n",
    "training = model_0.fit(X_train,y_train,batch_size = 128,epochs = 30,validation_split = 0.2,callbacks = tensorboard_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7750fec9",
   "metadata": {},
   "source": [
    "- **Plot the change in accuracy per epochs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eaddcdd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# list all data in training\n",
    "print(training.history.keys())\n",
    "# summarize training for accuracy\n",
    "plt.plot(training.history['accuracy'])\n",
    "plt.plot(training.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize traning for loss\n",
    "plt.plot(training.history['loss'])\n",
    "plt.plot(training.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5cb876",
   "metadata": {},
   "source": [
    "- **Evaluate the model on the testing data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e2fc217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 899us/step - loss: 0.5081 - accuracy: 0.8271\n",
      "Testing accuracy: 0.8270999789237976\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss,test_acc = model_0.evaluate(X_test,y_test)\n",
    "print(\"Testing accuracy:\",test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf7d584",
   "metadata": {},
   "source": [
    "- **Analyse the model summary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "430c74b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_layer (Dense)          (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_0.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27557361",
   "metadata": {},
   "source": [
    "- **Add hidden layer to the model to make it Multi-Layer Perceptron**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1c17fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = tf.keras.Sequential()\n",
    "N_hidden = 96\n",
    "# Adds a densely-connected layer with 96 units to the model\n",
    "model_1.add(Dense(N_hidden,name = 'dense_layer',input_shape = (784,),activation = 'relu'))\n",
    "# Now the model will take as input arrays of shape (*, 784) and ouput array of shape (*,64)\n",
    "\n",
    "# Adding another layer:\n",
    "model_1.add(Dense(N_hidden,name = 'dense_layer_2',activation = 'relu')) # after 1st layer we dont want to mention input shape\n",
    "\n",
    "# Add output layer with 10 output units (10 different classes)\n",
    "model_1.add(Dense(10,name = 'dense_layer_3',activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45e2145",
   "metadata": {},
   "source": [
    "- **Add Dropout to prevent overfitting and check its effect on accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96c31f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "# Most common type of model is a stack of layers\n",
    "model_2 = tf.keras.Sequential()\n",
    "n_hidden = 96\n",
    "\n",
    "# Adds a densely-connected layer with 64 units to the model:\n",
    "model_2.add(Dense(n_hidden,name = 'dense_layer',input_shape = (784,),activation = 'relu'))\n",
    "\n",
    "# Now the model will take as input arrays of shape (*, 784)# and output arrays of shape (*, 64)\n",
    "model_2.add(Dropout(0.4))\n",
    "\n",
    "# Adding another dense layer\n",
    "model_2.add(Dense(n_hidden,name = 'dense_layer_2',activation = 'relu'))\n",
    "model_2.add(Dropout(0.4))\n",
    "\n",
    "# Adding another dense layer:\n",
    "#model_2.add(Dense(N_hidden,name = 'dense_layer_3',activation = 'relu'))\n",
    "#model_2.add(Dropout(0.3))\n",
    "\n",
    "# Add an output layer with 10 output units (10 different classes):\n",
    "model_2.add(Dense(10,name = 'dense_layer_3',activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92cdec89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the model\n",
    "model_2.compile(optimizer = 'SGD',loss = 'categorical_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cdd15bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  2/375 [..............................] - ETA: 16s - loss: 2.4386 - accuracy: 0.0781WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0032s vs `on_train_batch_end` time: 0.0833s). Check your callbacks.\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.6886 - accuracy: 0.3994 - val_loss: 1.0211 - val_accuracy: 0.6769\n",
      "Epoch 2/30\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.1287 - accuracy: 0.5933 - val_loss: 0.7937 - val_accuracy: 0.7205\n",
      "Epoch 3/30\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.9589 - accuracy: 0.6528 - val_loss: 0.7099 - val_accuracy: 0.7483\n",
      "Epoch 4/30\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.8660 - accuracy: 0.6881 - val_loss: 0.6558 - val_accuracy: 0.7702\n",
      "Epoch 5/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.8058 - accuracy: 0.7152 - val_loss: 0.6179 - val_accuracy: 0.7824\n",
      "Epoch 6/30\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.7559 - accuracy: 0.7315 - val_loss: 0.5869 - val_accuracy: 0.7928\n",
      "Epoch 7/30\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.7244 - accuracy: 0.7447 - val_loss: 0.5628 - val_accuracy: 0.8025\n",
      "Epoch 8/30\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6962 - accuracy: 0.7550 - val_loss: 0.5438 - val_accuracy: 0.8091\n",
      "Epoch 9/30\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6729 - accuracy: 0.7649 - val_loss: 0.5267 - val_accuracy: 0.8134\n",
      "Epoch 10/30\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6494 - accuracy: 0.7729 - val_loss: 0.5120 - val_accuracy: 0.8201\n",
      "Epoch 11/30\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6340 - accuracy: 0.7796 - val_loss: 0.5008 - val_accuracy: 0.8203\n",
      "Epoch 12/30\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6208 - accuracy: 0.7846 - val_loss: 0.4918 - val_accuracy: 0.8255\n",
      "Epoch 13/30\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6041 - accuracy: 0.7882 - val_loss: 0.4806 - val_accuracy: 0.8272\n",
      "Epoch 14/30\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5942 - accuracy: 0.7921 - val_loss: 0.4746 - val_accuracy: 0.8291\n",
      "Epoch 15/30\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5819 - accuracy: 0.7982 - val_loss: 0.4682 - val_accuracy: 0.8320\n",
      "Epoch 16/30\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5749 - accuracy: 0.7992 - val_loss: 0.4609 - val_accuracy: 0.8335\n",
      "Epoch 17/30\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5665 - accuracy: 0.8023 - val_loss: 0.4548 - val_accuracy: 0.8348\n",
      "Epoch 18/30\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5556 - accuracy: 0.8073 - val_loss: 0.4516 - val_accuracy: 0.8342\n",
      "Epoch 19/30\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5464 - accuracy: 0.8100 - val_loss: 0.4464 - val_accuracy: 0.8377\n",
      "Epoch 20/30\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5423 - accuracy: 0.8116 - val_loss: 0.4414 - val_accuracy: 0.8386\n",
      "Epoch 21/30\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5367 - accuracy: 0.8134 - val_loss: 0.4378 - val_accuracy: 0.8412\n",
      "Epoch 22/30\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5292 - accuracy: 0.8140 - val_loss: 0.4347 - val_accuracy: 0.8411\n",
      "Epoch 23/30\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5253 - accuracy: 0.8167 - val_loss: 0.4303 - val_accuracy: 0.8423\n",
      "Epoch 24/30\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5213 - accuracy: 0.8196 - val_loss: 0.4285 - val_accuracy: 0.8457\n",
      "Epoch 25/30\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5158 - accuracy: 0.8205 - val_loss: 0.4234 - val_accuracy: 0.8475\n",
      "Epoch 26/30\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5149 - accuracy: 0.8196 - val_loss: 0.4215 - val_accuracy: 0.8468\n",
      "Epoch 27/30\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5060 - accuracy: 0.8228 - val_loss: 0.4185 - val_accuracy: 0.8469\n",
      "Epoch 28/30\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5011 - accuracy: 0.8240 - val_loss: 0.4164 - val_accuracy: 0.8492\n",
      "Epoch 29/30\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4978 - accuracy: 0.8274 - val_loss: 0.4137 - val_accuracy: 0.8496\n",
      "Epoch 30/30\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4954 - accuracy: 0.8294 - val_loss: 0.4120 - val_accuracy: 0.8497\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "log_dir = \"logs/fit/model2\"\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = log_dir,histogram_freq = 1)\n",
    "training = model_2.fit(X_train,y_train,batch_size = 128,epochs = 30,validation_split = 0.2,callbacks = tensorboard_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df79ad11",
   "metadata": {},
   "source": [
    "- When we did dropouts to avoid overfitting the accuracy slightly decreases "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a700fb9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.4352 - accuracy: 0.8422\n",
      "Test accuracy: 0.842199981212616\n"
     ]
    }
   ],
   "source": [
    "test_loss,test_acc = model_2.evaluate(X_test,y_test)\n",
    "print('Test accuracy:',test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0626ac9",
   "metadata": {},
   "source": [
    "- **Increasing the number of Hidden Layer neuron and check its effect on accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "32e7a7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = tf.keras.Sequential()\n",
    "N_hidden = 512\n",
    "# Adds a densely-connected layer with 64 units to the model:\n",
    "model_3.add(Dense(N_hidden,name = 'dense_Layer',input_shape = (784,),activation = 'relu'))\n",
    "model_3.add(Dropout(0.3))\n",
    "\n",
    "# Adding another dense layer:\n",
    "model_3.add(Dense(N_hidden,name = 'dense_layer_2',activation = 'relu'))\n",
    "model_3.add(Dropout(0.3))\n",
    "\n",
    "# Add an output layer with 10 output units (10 different classes):\n",
    "model_3.add(Dense(10,name = 'dense_layer_3',activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bee2a9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the model\n",
    "model_3.compile(optimizer = 'Adam',loss = 'categorical_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6917d02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  2/375 [..............................] - ETA: 24s - loss: 2.2925 - accuracy: 0.1094WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0184s vs `on_train_batch_end` time: 0.1131s). Check your callbacks.\n",
      "375/375 [==============================] - 8s 21ms/step - loss: 0.5930 - accuracy: 0.7846 - val_loss: 0.4178 - val_accuracy: 0.8466\n",
      "Epoch 2/30\n",
      "375/375 [==============================] - 8s 21ms/step - loss: 0.4264 - accuracy: 0.8451 - val_loss: 0.3715 - val_accuracy: 0.8649\n",
      "Epoch 3/30\n",
      "375/375 [==============================] - 7s 20ms/step - loss: 0.3911 - accuracy: 0.8575 - val_loss: 0.3613 - val_accuracy: 0.8694\n",
      "Epoch 4/30\n",
      "375/375 [==============================] - 8s 21ms/step - loss: 0.3614 - accuracy: 0.8698 - val_loss: 0.3449 - val_accuracy: 0.8736\n",
      "Epoch 5/30\n",
      "375/375 [==============================] - 8s 21ms/step - loss: 0.3521 - accuracy: 0.8718 - val_loss: 0.3442 - val_accuracy: 0.8766\n",
      "Epoch 6/30\n",
      "375/375 [==============================] - 8s 20ms/step - loss: 0.3391 - accuracy: 0.8755 - val_loss: 0.3375 - val_accuracy: 0.8798\n",
      "Epoch 7/30\n",
      "375/375 [==============================] - 8s 21ms/step - loss: 0.3273 - accuracy: 0.8794 - val_loss: 0.3171 - val_accuracy: 0.8845\n",
      "Epoch 8/30\n",
      "375/375 [==============================] - 8s 21ms/step - loss: 0.3202 - accuracy: 0.8810 - val_loss: 0.3344 - val_accuracy: 0.8802\n",
      "Epoch 9/30\n",
      "375/375 [==============================] - 8s 20ms/step - loss: 0.3137 - accuracy: 0.8820 - val_loss: 0.3166 - val_accuracy: 0.8817\n",
      "Epoch 10/30\n",
      "375/375 [==============================] - 8s 20ms/step - loss: 0.3016 - accuracy: 0.8887 - val_loss: 0.3245 - val_accuracy: 0.8846\n",
      "Epoch 11/30\n",
      "375/375 [==============================] - 8s 21ms/step - loss: 0.2974 - accuracy: 0.8886 - val_loss: 0.3127 - val_accuracy: 0.8877\n",
      "Epoch 12/30\n",
      "375/375 [==============================] - 7s 20ms/step - loss: 0.2889 - accuracy: 0.8920 - val_loss: 0.3142 - val_accuracy: 0.8918\n",
      "Epoch 13/30\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.2858 - accuracy: 0.8938 - val_loss: 0.3023 - val_accuracy: 0.8915\n",
      "Epoch 14/30\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.2772 - accuracy: 0.8969 - val_loss: 0.3131 - val_accuracy: 0.8892\n",
      "Epoch 15/30\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.2810 - accuracy: 0.8955 - val_loss: 0.3133 - val_accuracy: 0.8883\n",
      "Epoch 16/30\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.2717 - accuracy: 0.8971 - val_loss: 0.3158 - val_accuracy: 0.8869\n",
      "Epoch 17/30\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.2668 - accuracy: 0.9010 - val_loss: 0.3034 - val_accuracy: 0.8929\n",
      "Epoch 18/30\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.2661 - accuracy: 0.8985 - val_loss: 0.3107 - val_accuracy: 0.8945\n",
      "Epoch 19/30\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.2633 - accuracy: 0.9018 - val_loss: 0.3069 - val_accuracy: 0.8918\n",
      "Epoch 20/30\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.2547 - accuracy: 0.9035 - val_loss: 0.2962 - val_accuracy: 0.8966\n",
      "Epoch 21/30\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.2511 - accuracy: 0.9044 - val_loss: 0.2978 - val_accuracy: 0.8951\n",
      "Epoch 22/30\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.2511 - accuracy: 0.9051 - val_loss: 0.2933 - val_accuracy: 0.8968\n",
      "Epoch 23/30\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.2488 - accuracy: 0.9064 - val_loss: 0.2974 - val_accuracy: 0.8936\n",
      "Epoch 24/30\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.2427 - accuracy: 0.9096 - val_loss: 0.3004 - val_accuracy: 0.8913\n",
      "Epoch 25/30\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.2413 - accuracy: 0.9088 - val_loss: 0.3009 - val_accuracy: 0.8963\n",
      "Epoch 26/30\n",
      "375/375 [==============================] - 7s 20ms/step - loss: 0.2421 - accuracy: 0.9093 - val_loss: 0.3047 - val_accuracy: 0.8947\n",
      "Epoch 27/30\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.2376 - accuracy: 0.9111 - val_loss: 0.3043 - val_accuracy: 0.8941\n",
      "Epoch 28/30\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.2300 - accuracy: 0.9137 - val_loss: 0.3130 - val_accuracy: 0.8926\n",
      "Epoch 29/30\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.2316 - accuracy: 0.9119 - val_loss: 0.3013 - val_accuracy: 0.8968\n",
      "Epoch 30/30\n",
      "375/375 [==============================] - 7s 20ms/step - loss: 0.2248 - accuracy: 0.9161 - val_loss: 0.3101 - val_accuracy: 0.8943\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "log_dir = \"logs/fit/model3\"\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = log_dir,histogram_freq = 1)\n",
    "training = model_3.fit(X_train,y_train,batch_size = 128,epochs = 30,validation_split = 0.2,callbacks = tensorboard_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7a9207",
   "metadata": {},
   "source": [
    "- Adding hidden layer nueron the accuracy effects very good and in that **Adam** optimizer performs well "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4d5daa",
   "metadata": {},
   "source": [
    "- **Use different optimizers and check its effect on accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8e2ebb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets try with model_3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "34de02f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the model\n",
    "model_3.compile(optimizer = 'Adam',loss = 'categorical_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4f602e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  2/375 [..............................] - ETA: 24s - loss: 2.2381 - accuracy: 0.2305WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0149s vs `on_train_batch_end` time: 0.1153s). Check your callbacks.\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.5675 - accuracy: 0.7966 - val_loss: 0.4156 - val_accuracy: 0.8490\n",
      "Epoch 2/30\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.4110 - accuracy: 0.8495 - val_loss: 0.3645 - val_accuracy: 0.8677\n",
      "Epoch 3/30\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3794 - accuracy: 0.8605 - val_loss: 0.3597 - val_accuracy: 0.8672\n",
      "Epoch 4/30\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3525 - accuracy: 0.8694 - val_loss: 0.3497 - val_accuracy: 0.8715\n",
      "Epoch 5/30\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3374 - accuracy: 0.8739 - val_loss: 0.3304 - val_accuracy: 0.8792\n",
      "Epoch 6/30\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3233 - accuracy: 0.8783 - val_loss: 0.3321 - val_accuracy: 0.8785\n",
      "Epoch 7/30\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3134 - accuracy: 0.8827 - val_loss: 0.3190 - val_accuracy: 0.8851\n",
      "Epoch 8/30\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3015 - accuracy: 0.8865 - val_loss: 0.3492 - val_accuracy: 0.8698\n",
      "Epoch 9/30\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.2999 - accuracy: 0.8869 - val_loss: 0.3258 - val_accuracy: 0.8851\n",
      "Epoch 10/30\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.2945 - accuracy: 0.8890 - val_loss: 0.3042 - val_accuracy: 0.8889\n",
      "Epoch 11/30\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.2813 - accuracy: 0.8950 - val_loss: 0.3085 - val_accuracy: 0.8897\n",
      "Epoch 12/30\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.2745 - accuracy: 0.8957 - val_loss: 0.3218 - val_accuracy: 0.8843\n",
      "Epoch 13/30\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.2702 - accuracy: 0.8975 - val_loss: 0.3221 - val_accuracy: 0.8883\n",
      "Epoch 14/30\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.2651 - accuracy: 0.9000 - val_loss: 0.3180 - val_accuracy: 0.8863\n",
      "Epoch 15/30\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.2565 - accuracy: 0.9034 - val_loss: 0.3068 - val_accuracy: 0.8909\n",
      "Epoch 16/30\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.2553 - accuracy: 0.9024 - val_loss: 0.3126 - val_accuracy: 0.8887\n",
      "Epoch 17/30\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.2468 - accuracy: 0.9067 - val_loss: 0.3031 - val_accuracy: 0.8938\n",
      "Epoch 18/30\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.2428 - accuracy: 0.9078 - val_loss: 0.3007 - val_accuracy: 0.8911\n",
      "Epoch 19/30\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.2430 - accuracy: 0.9068 - val_loss: 0.2951 - val_accuracy: 0.8967\n",
      "Epoch 20/30\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.2367 - accuracy: 0.9105 - val_loss: 0.2962 - val_accuracy: 0.8924\n",
      "Epoch 21/30\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.2355 - accuracy: 0.9099 - val_loss: 0.2995 - val_accuracy: 0.8941\n",
      "Epoch 22/30\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.2302 - accuracy: 0.9119 - val_loss: 0.3002 - val_accuracy: 0.8939\n",
      "Epoch 23/30\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.2290 - accuracy: 0.9118 - val_loss: 0.2958 - val_accuracy: 0.8968\n",
      "Epoch 24/30\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.2219 - accuracy: 0.9147 - val_loss: 0.3162 - val_accuracy: 0.8916\n",
      "Epoch 25/30\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.2204 - accuracy: 0.9150 - val_loss: 0.2972 - val_accuracy: 0.8957\n",
      "Epoch 26/30\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.2166 - accuracy: 0.9164 - val_loss: 0.2947 - val_accuracy: 0.9000\n",
      "Epoch 27/30\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.2158 - accuracy: 0.9174 - val_loss: 0.3014 - val_accuracy: 0.8982\n",
      "Epoch 28/30\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.2109 - accuracy: 0.9202 - val_loss: 0.3097 - val_accuracy: 0.8962\n",
      "Epoch 29/30\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.2098 - accuracy: 0.9195 - val_loss: 0.3001 - val_accuracy: 0.8934\n",
      "Epoch 30/30\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.2028 - accuracy: 0.9222 - val_loss: 0.2987 - val_accuracy: 0.9012\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "log_dir = \"logs/fit/model3\"\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = log_dir,histogram_freq = 1)\n",
    "training = model_3.fit(X_train,y_train,batch_size = 128,epochs = 30,validation_split = 0.2,callbacks = tensorboard_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f0ad444a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.compile(optimizer = 'rmsprop',loss = 'categorical_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "79b8dd5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  2/375 [..............................] - ETA: 20s - loss: 0.1862 - accuracy: 0.9180WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0179s vs `on_train_batch_end` time: 0.0917s). Check your callbacks.\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.2059 - accuracy: 0.9225 - val_loss: 0.3432 - val_accuracy: 0.8963\n",
      "Epoch 2/30\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.2075 - accuracy: 0.9225 - val_loss: 0.3567 - val_accuracy: 0.8940\n",
      "Epoch 3/30\n",
      "375/375 [==============================] - 7s 20ms/step - loss: 0.2054 - accuracy: 0.9254 - val_loss: 0.3664 - val_accuracy: 0.8929\n",
      "Epoch 4/30\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.2038 - accuracy: 0.9255 - val_loss: 0.3490 - val_accuracy: 0.8994\n",
      "Epoch 5/30\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.2099 - accuracy: 0.9235 - val_loss: 0.3672 - val_accuracy: 0.9015\n",
      "Epoch 6/30\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.2069 - accuracy: 0.9244 - val_loss: 0.3665 - val_accuracy: 0.9013\n",
      "Epoch 7/30\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.2078 - accuracy: 0.9247 - val_loss: 0.3736 - val_accuracy: 0.8995\n",
      "Epoch 8/30\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.2120 - accuracy: 0.9248 - val_loss: 0.3511 - val_accuracy: 0.9021\n",
      "Epoch 9/30\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.2114 - accuracy: 0.9228 - val_loss: 0.4110 - val_accuracy: 0.8997\n",
      "Epoch 10/30\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.2099 - accuracy: 0.9249 - val_loss: 0.4105 - val_accuracy: 0.8990\n",
      "Epoch 11/30\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.2110 - accuracy: 0.9252 - val_loss: 0.3907 - val_accuracy: 0.9016\n",
      "Epoch 12/30\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.2091 - accuracy: 0.9266 - val_loss: 0.4289 - val_accuracy: 0.8972\n",
      "Epoch 13/30\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.2105 - accuracy: 0.9260 - val_loss: 0.4127 - val_accuracy: 0.8986\n",
      "Epoch 14/30\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.2096 - accuracy: 0.9261 - val_loss: 0.4669 - val_accuracy: 0.8956\n",
      "Epoch 15/30\n",
      "375/375 [==============================] - 7s 17ms/step - loss: 0.2104 - accuracy: 0.9268 - val_loss: 0.4268 - val_accuracy: 0.8981\n",
      "Epoch 16/30\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.2059 - accuracy: 0.9283 - val_loss: 0.4395 - val_accuracy: 0.8996\n",
      "Epoch 17/30\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.2118 - accuracy: 0.9278 - val_loss: 0.4381 - val_accuracy: 0.8975loss: 0.2120 - accuracy\n",
      "Epoch 18/30\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.2128 - accuracy: 0.9268 - val_loss: 0.4450 - val_accuracy: 0.8939\n",
      "Epoch 19/30\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.2111 - accuracy: 0.9268 - val_loss: 0.4178 - val_accuracy: 0.8961\n",
      "Epoch 20/30\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.2089 - accuracy: 0.9288 - val_loss: 0.4447 - val_accuracy: 0.8963\n",
      "Epoch 21/30\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.2125 - accuracy: 0.9293 - val_loss: 0.4638 - val_accuracy: 0.8938\n",
      "Epoch 22/30\n",
      "375/375 [==============================] - 7s 17ms/step - loss: 0.2113 - accuracy: 0.9287 - val_loss: 0.4688 - val_accuracy: 0.8960\n",
      "Epoch 23/30\n",
      "375/375 [==============================] - 7s 17ms/step - loss: 0.2128 - accuracy: 0.9277 - val_loss: 0.4495 - val_accuracy: 0.8991\n",
      "Epoch 24/30\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.2119 - accuracy: 0.9280 - val_loss: 0.4505 - val_accuracy: 0.8992\n",
      "Epoch 25/30\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.2094 - accuracy: 0.9294 - val_loss: 0.4681 - val_accuracy: 0.8989\n",
      "Epoch 26/30\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.2120 - accuracy: 0.9300 - val_loss: 0.4721 - val_accuracy: 0.8997\n",
      "Epoch 27/30\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.2073 - accuracy: 0.9300 - val_loss: 0.4621 - val_accuracy: 0.8986\n",
      "Epoch 28/30\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.2059 - accuracy: 0.9305 - val_loss: 0.5227 - val_accuracy: 0.8997\n",
      "Epoch 29/30\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.2098 - accuracy: 0.9314 - val_loss: 0.4927 - val_accuracy: 0.8967\n",
      "Epoch 30/30\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.2071 - accuracy: 0.9298 - val_loss: 0.4853 - val_accuracy: 0.9008\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "log_dir = \"logs/fit/model3\"\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = log_dir,histogram_freq = 1)\n",
    "training = model_3.fit(X_train,y_train,batch_size = 128,epochs = 30,validation_split = 0.2,callbacks = tensorboard_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "37a0b0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.compile(optimizer = 'sgd',loss = 'categorical_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ed8a4674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  2/375 [..............................] - ETA: 19s - loss: 0.2064 - accuracy: 0.9375WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0147s vs `on_train_batch_end` time: 0.0903s). Check your callbacks.\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.1727 - accuracy: 0.9409 - val_loss: 0.4587 - val_accuracy: 0.9045\n",
      "Epoch 2/30\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.1563 - accuracy: 0.9441 - val_loss: 0.4570 - val_accuracy: 0.9062\n",
      "Epoch 3/30\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.1522 - accuracy: 0.9469 - val_loss: 0.4548 - val_accuracy: 0.9068\n",
      "Epoch 4/30\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.1438 - accuracy: 0.9489 - val_loss: 0.4587 - val_accuracy: 0.9068\n",
      "Epoch 5/30\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.1409 - accuracy: 0.9492 - val_loss: 0.4585 - val_accuracy: 0.9072\n",
      "Epoch 6/30\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.1405 - accuracy: 0.9493 - val_loss: 0.4579 - val_accuracy: 0.9077\n",
      "Epoch 7/30\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.1371 - accuracy: 0.9504 - val_loss: 0.4627 - val_accuracy: 0.9072\n",
      "Epoch 8/30\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.1388 - accuracy: 0.9512 - val_loss: 0.4593 - val_accuracy: 0.9079\n",
      "Epoch 9/30\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.1331 - accuracy: 0.9520 - val_loss: 0.4648 - val_accuracy: 0.9068\n",
      "Epoch 10/30\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.1350 - accuracy: 0.9510 - val_loss: 0.4612 - val_accuracy: 0.9075\n",
      "Epoch 11/30\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.1294 - accuracy: 0.9524 - val_loss: 0.4661 - val_accuracy: 0.9078\n",
      "Epoch 12/30\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.1318 - accuracy: 0.9520 - val_loss: 0.4663 - val_accuracy: 0.9073\n",
      "Epoch 13/30\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.1294 - accuracy: 0.9527 - val_loss: 0.4663 - val_accuracy: 0.9077\n",
      "Epoch 14/30\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.1304 - accuracy: 0.9538 - val_loss: 0.4681 - val_accuracy: 0.9064\n",
      "Epoch 15/30\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.1300 - accuracy: 0.9529 - val_loss: 0.4643 - val_accuracy: 0.9082\n",
      "Epoch 16/30\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.1297 - accuracy: 0.9516 - val_loss: 0.4683 - val_accuracy: 0.9069\n",
      "Epoch 17/30\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.1263 - accuracy: 0.9537 - val_loss: 0.4705 - val_accuracy: 0.9061\n",
      "Epoch 18/30\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.1250 - accuracy: 0.9544 - val_loss: 0.4686 - val_accuracy: 0.9081\n",
      "Epoch 19/30\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.1244 - accuracy: 0.9546 - val_loss: 0.4704 - val_accuracy: 0.9078\n",
      "Epoch 20/30\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.1281 - accuracy: 0.9527 - val_loss: 0.4727 - val_accuracy: 0.9081\n",
      "Epoch 21/30\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.1275 - accuracy: 0.9542 - val_loss: 0.4710 - val_accuracy: 0.9081\n",
      "Epoch 22/30\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.1231 - accuracy: 0.9540 - val_loss: 0.4718 - val_accuracy: 0.9085\n",
      "Epoch 23/30\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.1263 - accuracy: 0.9530 - val_loss: 0.4720 - val_accuracy: 0.9082\n",
      "Epoch 24/30\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.1240 - accuracy: 0.9544 - val_loss: 0.4747 - val_accuracy: 0.9086\n",
      "Epoch 25/30\n",
      "375/375 [==============================] - 5s 15ms/step - loss: 0.1228 - accuracy: 0.9536 - val_loss: 0.4773 - val_accuracy: 0.9068\n",
      "Epoch 26/30\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.1210 - accuracy: 0.9547 - val_loss: 0.4746 - val_accuracy: 0.9073\n",
      "Epoch 27/30\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.1216 - accuracy: 0.9554 - val_loss: 0.4763 - val_accuracy: 0.9082\n",
      "Epoch 28/30\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.1209 - accuracy: 0.9556 - val_loss: 0.4719 - val_accuracy: 0.9069\n",
      "Epoch 29/30\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.1231 - accuracy: 0.9541 - val_loss: 0.4720 - val_accuracy: 0.9078\n",
      "Epoch 30/30\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.1215 - accuracy: 0.9553 - val_loss: 0.4723 - val_accuracy: 0.9077\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "log_dir = \"logs/fit/model3\"\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = log_dir,histogram_freq = 1)\n",
    "training = model_3.fit(X_train,y_train,batch_size = 128,epochs = 30,validation_split = 0.2,callbacks = tensorboard_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37dd6a1",
   "metadata": {},
   "source": [
    "- Comparing to all optimizers the **SGD** is showing best accuracy 0.9553, **Adam** accuracy is 0.9298 and **rmsprop** accuracy is 0.9222, so, comparing all optimizers SGD is giving better perfomance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674f3bc2",
   "metadata": {},
   "source": [
    "- **Increase the hidden layers and check its effect on accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eb27407b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# In keras, layers are assembled to build a models\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "#Most common type of model is a stack of layers\n",
    "\n",
    "model_4 = tf.keras.Sequential()\n",
    "N_hidden = 512\n",
    "\n",
    "# Adds a densely-connected layer with 64 units to the model:\n",
    "model_4.add(Dense(N_hidden,name = 'dense_Layer',input_shape = (784,),activation = 'relu'))\n",
    "model_4.add(Dropout(0.3))\n",
    "\n",
    "# Adding another dense layer:\n",
    "model_4.add(Dense(N_hidden,name = 'dense_layer_2',activation = 'relu'))\n",
    "model_4.add(Dropout(0.3))\n",
    "\n",
    "# Adding another dense layer:\n",
    "model_4.add(Dense(N_hidden,name = 'dense_layer_3',activation = 'relu'))\n",
    "model_4.add(Dropout(0.3))\n",
    "\n",
    "# Add an output layer with 10 output units (10 different classes):\n",
    "model_4.add(Dense(10,name = 'dense_layer_4',activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "91a5f56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4.compile(optimizer = 'sgd',loss = 'categorical_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7592ffbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  2/375 [..............................] - ETA: 12s - loss: 2.3847 - accuracy: 0.0664WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0128s vs `on_train_batch_end` time: 0.0531s). Check your callbacks.\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 1.4137 - accuracy: 0.5075 - val_loss: 0.7891 - val_accuracy: 0.7266\n",
      "Epoch 2/30\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.8545 - accuracy: 0.6928 - val_loss: 0.6484 - val_accuracy: 0.7678\n",
      "Epoch 3/30\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.7315 - accuracy: 0.7405 - val_loss: 0.5858 - val_accuracy: 0.7907\n",
      "Epoch 4/30\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.6626 - accuracy: 0.7661 - val_loss: 0.5428 - val_accuracy: 0.8073\n",
      "Epoch 5/30\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.6131 - accuracy: 0.7854 - val_loss: 0.5139 - val_accuracy: 0.8158\n",
      "Epoch 6/30\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.5784 - accuracy: 0.7964 - val_loss: 0.4904 - val_accuracy: 0.8253\n",
      "Epoch 7/30\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5585 - accuracy: 0.8030 - val_loss: 0.4789 - val_accuracy: 0.8278\n",
      "Epoch 8/30\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.5321 - accuracy: 0.8137 - val_loss: 0.4628 - val_accuracy: 0.8327\n",
      "Epoch 9/30\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.5144 - accuracy: 0.8187 - val_loss: 0.4487 - val_accuracy: 0.8384\n",
      "Epoch 10/30\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.4983 - accuracy: 0.8234 - val_loss: 0.4359 - val_accuracy: 0.8435\n",
      "Epoch 11/30\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.4847 - accuracy: 0.8294 - val_loss: 0.4282 - val_accuracy: 0.8452\n",
      "Epoch 12/30\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.4751 - accuracy: 0.8327 - val_loss: 0.4221 - val_accuracy: 0.8483\n",
      "Epoch 13/30\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4655 - accuracy: 0.8356 - val_loss: 0.4159 - val_accuracy: 0.8506\n",
      "Epoch 14/30\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4549 - accuracy: 0.8396 - val_loss: 0.4093 - val_accuracy: 0.8517\n",
      "Epoch 15/30\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.4462 - accuracy: 0.8430 - val_loss: 0.4058 - val_accuracy: 0.8515\n",
      "Epoch 16/30\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.4403 - accuracy: 0.8444 - val_loss: 0.3974 - val_accuracy: 0.8561\n",
      "Epoch 17/30\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.4323 - accuracy: 0.8447 - val_loss: 0.3933 - val_accuracy: 0.8591\n",
      "Epoch 18/30\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.4270 - accuracy: 0.8489 - val_loss: 0.3871 - val_accuracy: 0.8602\n",
      "Epoch 19/30\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.4202 - accuracy: 0.8504 - val_loss: 0.3849 - val_accuracy: 0.8627\n",
      "Epoch 20/30\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.4107 - accuracy: 0.8548 - val_loss: 0.3832 - val_accuracy: 0.8628\n",
      "Epoch 21/30\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.4096 - accuracy: 0.8549 - val_loss: 0.3767 - val_accuracy: 0.8636\n",
      "Epoch 22/30\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.4034 - accuracy: 0.8559 - val_loss: 0.3747 - val_accuracy: 0.8647\n",
      "Epoch 23/30\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.4005 - accuracy: 0.8583 - val_loss: 0.3716 - val_accuracy: 0.8683\n",
      "Epoch 24/30\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.3914 - accuracy: 0.8612 - val_loss: 0.3668 - val_accuracy: 0.8675\n",
      "Epoch 25/30\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.3892 - accuracy: 0.8619 - val_loss: 0.3636 - val_accuracy: 0.8708\n",
      "Epoch 26/30\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.3836 - accuracy: 0.8612 - val_loss: 0.3632 - val_accuracy: 0.8706\n",
      "Epoch 27/30\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3823 - accuracy: 0.8635 - val_loss: 0.3593 - val_accuracy: 0.8691\n",
      "Epoch 28/30\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.3780 - accuracy: 0.8654 - val_loss: 0.3587 - val_accuracy: 0.8720\n",
      "Epoch 29/30\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3750 - accuracy: 0.8659 - val_loss: 0.3553 - val_accuracy: 0.8743\n",
      "Epoch 30/30\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.3713 - accuracy: 0.8664 - val_loss: 0.3510 - val_accuracy: 0.8759\n"
     ]
    }
   ],
   "source": [
    "# Training the model. \n",
    "log_dir = \"logs/fit/model4\"\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "training = model_4.fit(X_train, y_train, batch_size=128, epochs=30, validation_split=0.2,callbacks=tensorboard_callback) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04e533f",
   "metadata": {},
   "source": [
    "- when hidden layer increases the accuracy decreased here  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e66b8b1",
   "metadata": {},
   "source": [
    "- **Manipulate the batch_size and epochs and check its effect on accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "27f2e0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5 = tf.keras.Sequential()\n",
    "N_hidden = 512\n",
    "# Adds a densely-connected layer with 64 units to the model:\n",
    "model_5.add(Dense(N_hidden,name = 'dense_Layer',input_shape = (784,),activation = 'relu'))\n",
    "model_5.add(Dropout(0.3))\n",
    "\n",
    "# Adding another dense layer:\n",
    "model_5.add(Dense(N_hidden,name = 'dense_layer_2',activation = 'relu'))\n",
    "model_5.add(Dropout(0.3))\n",
    "\n",
    "# Add an output layer with 10 output units (10 different classes):\n",
    "model_5.add(Dense(10,name = 'dense_layer_3',activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "07c84454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the model\n",
    "model_5.compile(optimizer = 'Adam',loss = 'categorical_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ee997bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "  2/188 [..............................] - ETA: 6s - loss: 2.1719 - accuracy: 0.1992WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0152s vs `on_train_batch_end` time: 0.0590s). Check your callbacks.\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.6055 - accuracy: 0.7849 - val_loss: 0.4319 - val_accuracy: 0.8393\n",
      "Epoch 2/50\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.4203 - accuracy: 0.8474 - val_loss: 0.3887 - val_accuracy: 0.8575\n",
      "Epoch 3/50\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.3782 - accuracy: 0.8613 - val_loss: 0.3574 - val_accuracy: 0.8690\n",
      "Epoch 4/50\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.3548 - accuracy: 0.8689 - val_loss: 0.3599 - val_accuracy: 0.8665\n",
      "Epoch 5/50\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.3354 - accuracy: 0.8772 - val_loss: 0.3503 - val_accuracy: 0.8695\n",
      "Epoch 6/50\n",
      "188/188 [==============================] - 2s 12ms/step - loss: 0.3202 - accuracy: 0.8811 - val_loss: 0.3260 - val_accuracy: 0.8833\n",
      "Epoch 7/50\n",
      "188/188 [==============================] - 2s 12ms/step - loss: 0.3108 - accuracy: 0.8849 - val_loss: 0.3197 - val_accuracy: 0.8827\n",
      "Epoch 8/50\n",
      "188/188 [==============================] - 2s 12ms/step - loss: 0.2992 - accuracy: 0.8892 - val_loss: 0.3148 - val_accuracy: 0.8861\n",
      "Epoch 9/50\n",
      "188/188 [==============================] - 2s 12ms/step - loss: 0.2891 - accuracy: 0.8922 - val_loss: 0.3070 - val_accuracy: 0.8882\n",
      "Epoch 10/50\n",
      "188/188 [==============================] - 2s 12ms/step - loss: 0.2801 - accuracy: 0.8957 - val_loss: 0.3073 - val_accuracy: 0.8896\n",
      "Epoch 11/50\n",
      "188/188 [==============================] - 2s 12ms/step - loss: 0.2769 - accuracy: 0.8963 - val_loss: 0.3085 - val_accuracy: 0.8898\n",
      "Epoch 12/50\n",
      "188/188 [==============================] - 2s 12ms/step - loss: 0.2690 - accuracy: 0.8992 - val_loss: 0.2999 - val_accuracy: 0.8923\n",
      "Epoch 13/50\n",
      "188/188 [==============================] - 2s 12ms/step - loss: 0.2628 - accuracy: 0.9021 - val_loss: 0.3097 - val_accuracy: 0.8905\n",
      "Epoch 14/50\n",
      "188/188 [==============================] - 2s 12ms/step - loss: 0.2623 - accuracy: 0.9023 - val_loss: 0.2981 - val_accuracy: 0.8952\n",
      "Epoch 15/50\n",
      "188/188 [==============================] - 2s 12ms/step - loss: 0.2530 - accuracy: 0.9045 - val_loss: 0.2929 - val_accuracy: 0.8937\n",
      "Epoch 16/50\n",
      "188/188 [==============================] - 2s 12ms/step - loss: 0.2455 - accuracy: 0.9072 - val_loss: 0.3039 - val_accuracy: 0.8938\n",
      "Epoch 17/50\n",
      "188/188 [==============================] - 2s 12ms/step - loss: 0.2440 - accuracy: 0.9069 - val_loss: 0.2956 - val_accuracy: 0.8936\n",
      "Epoch 18/50\n",
      "188/188 [==============================] - 2s 12ms/step - loss: 0.2383 - accuracy: 0.9104 - val_loss: 0.3028 - val_accuracy: 0.8913\n",
      "Epoch 19/50\n",
      "188/188 [==============================] - 2s 12ms/step - loss: 0.2316 - accuracy: 0.9125 - val_loss: 0.2968 - val_accuracy: 0.8942\n",
      "Epoch 20/50\n",
      "188/188 [==============================] - 2s 12ms/step - loss: 0.2303 - accuracy: 0.9128 - val_loss: 0.2999 - val_accuracy: 0.8957\n",
      "Epoch 21/50\n",
      "188/188 [==============================] - 2s 12ms/step - loss: 0.2245 - accuracy: 0.9136 - val_loss: 0.2927 - val_accuracy: 0.8935\n",
      "Epoch 22/50\n",
      "188/188 [==============================] - 2s 12ms/step - loss: 0.2225 - accuracy: 0.9160 - val_loss: 0.3044 - val_accuracy: 0.8908\n",
      "Epoch 23/50\n",
      "188/188 [==============================] - 2s 12ms/step - loss: 0.2172 - accuracy: 0.9177 - val_loss: 0.2966 - val_accuracy: 0.8940\n",
      "Epoch 24/50\n",
      "188/188 [==============================] - 2s 12ms/step - loss: 0.2140 - accuracy: 0.9183 - val_loss: 0.2903 - val_accuracy: 0.8975\n",
      "Epoch 25/50\n",
      "188/188 [==============================] - 2s 12ms/step - loss: 0.2111 - accuracy: 0.9197 - val_loss: 0.2984 - val_accuracy: 0.8963\n",
      "Epoch 26/50\n",
      "188/188 [==============================] - 2s 12ms/step - loss: 0.2114 - accuracy: 0.9191 - val_loss: 0.2863 - val_accuracy: 0.9007\n",
      "Epoch 27/50\n",
      "188/188 [==============================] - 2s 13ms/step - loss: 0.2070 - accuracy: 0.9214 - val_loss: 0.3069 - val_accuracy: 0.8964\n",
      "Epoch 28/50\n",
      "188/188 [==============================] - 3s 13ms/step - loss: 0.2062 - accuracy: 0.9225 - val_loss: 0.2988 - val_accuracy: 0.8986\n",
      "Epoch 29/50\n",
      "188/188 [==============================] - 2s 13ms/step - loss: 0.2007 - accuracy: 0.9230 - val_loss: 0.2930 - val_accuracy: 0.8978\n",
      "Epoch 30/50\n",
      "188/188 [==============================] - 2s 13ms/step - loss: 0.1965 - accuracy: 0.9245 - val_loss: 0.3014 - val_accuracy: 0.8977\n",
      "Epoch 31/50\n",
      "188/188 [==============================] - 2s 13ms/step - loss: 0.1919 - accuracy: 0.9268 - val_loss: 0.3047 - val_accuracy: 0.8953\n",
      "Epoch 32/50\n",
      "188/188 [==============================] - 2s 13ms/step - loss: 0.1958 - accuracy: 0.9251 - val_loss: 0.3054 - val_accuracy: 0.8989\n",
      "Epoch 33/50\n",
      "188/188 [==============================] - 2s 13ms/step - loss: 0.1915 - accuracy: 0.9276 - val_loss: 0.3052 - val_accuracy: 0.8955\n",
      "Epoch 34/50\n",
      "188/188 [==============================] - 2s 13ms/step - loss: 0.1858 - accuracy: 0.9293 - val_loss: 0.2953 - val_accuracy: 0.9014\n",
      "Epoch 35/50\n",
      "188/188 [==============================] - 2s 13ms/step - loss: 0.1818 - accuracy: 0.9303 - val_loss: 0.3006 - val_accuracy: 0.8996\n",
      "Epoch 36/50\n",
      "188/188 [==============================] - 2s 13ms/step - loss: 0.1850 - accuracy: 0.9281 - val_loss: 0.3046 - val_accuracy: 0.8982\n",
      "Epoch 37/50\n",
      "188/188 [==============================] - 2s 13ms/step - loss: 0.1754 - accuracy: 0.9326 - val_loss: 0.2994 - val_accuracy: 0.8991\n",
      "Epoch 38/50\n",
      "188/188 [==============================] - 2s 13ms/step - loss: 0.1791 - accuracy: 0.9310 - val_loss: 0.3218 - val_accuracy: 0.9017\n",
      "Epoch 39/50\n",
      "188/188 [==============================] - 2s 13ms/step - loss: 0.1746 - accuracy: 0.9333 - val_loss: 0.3075 - val_accuracy: 0.8995\n",
      "Epoch 40/50\n",
      "188/188 [==============================] - 2s 13ms/step - loss: 0.1753 - accuracy: 0.9345 - val_loss: 0.3056 - val_accuracy: 0.9011\n",
      "Epoch 41/50\n",
      "188/188 [==============================] - 2s 13ms/step - loss: 0.1701 - accuracy: 0.9358 - val_loss: 0.3081 - val_accuracy: 0.9009\n",
      "Epoch 42/50\n",
      "188/188 [==============================] - 2s 13ms/step - loss: 0.1688 - accuracy: 0.9354 - val_loss: 0.3084 - val_accuracy: 0.9017\n",
      "Epoch 43/50\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.1697 - accuracy: 0.9354 - val_loss: 0.3139 - val_accuracy: 0.8990\n",
      "Epoch 44/50\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.1663 - accuracy: 0.9369 - val_loss: 0.3044 - val_accuracy: 0.9001\n",
      "Epoch 45/50\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.1634 - accuracy: 0.9377 - val_loss: 0.3052 - val_accuracy: 0.9024\n",
      "Epoch 46/50\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.1575 - accuracy: 0.9396 - val_loss: 0.3151 - val_accuracy: 0.9014\n",
      "Epoch 47/50\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.1621 - accuracy: 0.9389 - val_loss: 0.3200 - val_accuracy: 0.9029\n",
      "Epoch 48/50\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.1598 - accuracy: 0.9389 - val_loss: 0.3163 - val_accuracy: 0.9005\n",
      "Epoch 49/50\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.1574 - accuracy: 0.9379 - val_loss: 0.3228 - val_accuracy: 0.8985\n",
      "Epoch 50/50\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.1580 - accuracy: 0.9401 - val_loss: 0.3146 - val_accuracy: 0.9026\n"
     ]
    }
   ],
   "source": [
    "# Training the model. \n",
    "log_dir = \"logs/fit/model5\"\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "training = model_5.fit(X_train, y_train, batch_size=256, epochs=50, validation_split=0.2,callbacks=tensorboard_callback) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89759da",
   "metadata": {},
   "source": [
    "- Here, the accuracy is good, its fit the model very good the accuracy is 0.9401 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88bcab5",
   "metadata": {},
   "source": [
    "- **Answer: What parameters should be choosen to get best accuracy on classifying the images into various categories?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d8b314",
   "metadata": {},
   "source": [
    "- To get best accuracy use \"SGD\" paramater, and **Adam** is also performs very well we cannot say its depends upon how the complexity the problem was \n",
    "- activation is also helps us to get good accuarcy \"relu\" or \"softmax\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54769273",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39e7cf41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=2, n_estimators=None, random_state=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForestClassifier(n_estimators = None,max_depth=2, random_state=0,n_jobs = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b03271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b6f10f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'Feature_importances_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mAdaBoostClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_estimators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mFeature_importances_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\2.anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m extra_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(all_args)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extra_args \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# extra_args > 0\u001b[39;00m\n\u001b[0;32m     66\u001b[0m args_msg \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name, arg)\n\u001b[0;32m     67\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m name, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(kwonly_args[:extra_args],\n\u001b[0;32m     68\u001b[0m                                  args[\u001b[38;5;241m-\u001b[39mextra_args:])]\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'Feature_importances_'"
     ]
    }
   ],
   "source": [
    "AdaBoostClassifier(n_estimators=100, random_state=0,learning_rate = None,Feature_importances_= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b1f21c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
